# CLEF Health 2015

*This folder contains all the code developed while working on the assignment. You can find more details on the report, on ```report/```, while all the developed code is on  divided across the other folders, the section "Organisation" details how they are distributed. This readme just discusses how to install and use the project, it doesn't discusses technical aspects related to IR. For this kind of information, please refer to the report (or the slides [to be added]).*

## Organisation

Each folder contains the following files:

* **CHV:** The code used to perform Query Expansion based on the Consumer Health Vocabulary (available on http://consumerhealthvocab.org/)
* **HTML_cleaner:** A python script that uses BeautifulSoup and LXML to parse the original HTML files from the corpus. Further instructions can be found on the section *"Removing the HTML tags from the corpus"*.
* **src:** Constains the Java code developed atop of Terrier. It has the Dirichlet-JM Language Model, EMIM and CHV Query Expansions and Mu-Tunning. You can find more information about the code on ```doc/``` or on the report.
* **doc:** Javadoc for the files on ```src/```.
* **bin:** Binaries generated by Eclipse when compiling the core Java code.
* **libs:** Contains all external dependencies used on this code, including Terrier jars.
* **tools:** This folder contains both original and expanded queries and two utilities scripts. More information about them below and on this folder's readme. This folder also contains the zipped obtained results on ```results.zip```. For more information about which queries and configurations generated each output, refer to the report.

## Getting started

The basic workflow consists in removing the HTML tags from the original corpus, generating a new collection and indexing it using Terrier.

On the other hand, expansion is performed on the original queries using the developed code, then retrieval can be by using the developed code.

### Removing the HTML tags from the corpus

To do so, run ```HTML_cleaner/filter.py```. In order to do so, you'll need Python 2.x, BeautifulSoup and lxml. These dependencies can be resolved though pip using ```pip install beautifulsoup4``` and ```pip install lxml```.

This script takes two parameters, the corpus collection path and the cleaned collection destination. You can set the origin path as destination, this will cause Python to replace the HTML files on the fly, although this is not recommended.

If a HTML file is too long, causing BeautifulSoup to throw a ```tooDeepStack``` exception, its parsing will fail. On this case, the script will keep this file ID (its sequential number) and resume the parsing from the next one. At the end of the operation, a list of problematic files is displayed.

### Indexing with Terrier

To index run the command on ```tools/index_terrier.sh```. You'll need to setup the parameters according to your environment propertly. No bash script was written to do so because this step is completed just once and most of the command onsists on parameters that depends on your configurations.

### Performing query expansion and retrieval

The developed Java code can be seen as a framework that allows different course of actions. You can:

* Retrieve from the index using the original queries
* Expand the queries using different expanding policies (refer to the report to learn more about them)
* Expand based only on CHV or using both CHV and EMIM
* Save the expanded queries
* Run the whole pipeline and perform retrieval using either Dirichlet, Jelinek-Mercer or Two-Stage Language Smoothing techniques
* Set values for λ and μ manuallu
* Tune μ according to the corpus

For detailed informatino about how to use the code, refer to ```doc/```

In order to prepare the output file to be evaluated using *trec_eval* tags are appended to the file. Unfortunately, some of them have to be removed. To do
so, use ```tools/retrieve_terrier.sh```. This script remove these tags, performs the evaluation and saves the performance report as a file informed as a parameter before running the script (except if the flag ```-d``` is used).

### Retrieving with Terrier

You can, alternativelly, perform retrieval using Terrier. To do so, the same script ```tools/retrieve_terrier.sh``` can be used, but in this case the flag ```-d -t``` must be informed. Unfortunately the later parameter depends on the first, so you may need to modify the script by yourlself (this is a pending improvment). By default, Terrier will perform the retrieval using Dirichlet Language Model (only) with the standard value for μ (2500 on version 4).
